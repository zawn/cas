---
layout: 违约
title: CAS - 高可用性指南
category: 高可用性
---

# 高可用性指南（HA/聚类）

高度可用的 CAS 部署可针对各种故障模式提供弹性，因此 CAS 尽管失败仍继续提供 SSO 服务。 我们提供推荐的架构，为 规划和执行符合机构绩效和可用性要求的 CAS 部署提供起点。 它还为理解 HA 考虑所强加的 CAS 软件组件要求提供了一个框架。

CAS 的高可用性 （HA） 配置通过确保有足够的冗余来实现，以便 在零件故障面前保持强大的服务，并且无需停机即可进行常规维护。 这可以通过多节点实现，在较小程度上，单节点CAS具有先进的虚拟机功能。 本文档将侧重于实现 HA 所需的 CAS 服务器组件。 对医管局配置进行更定量的分析 取决于支持基础设施和服务，超出了本文件的范围。

CAS服务器软件有着非常可靠的记录。 然而，CAS服务器只是软件和硬件的一小部分 ，认证必须经过才能顺利工作。 聚类通常 不仅用于负载处理，还用于故障处理。 即使没有发生故障，重新启动服务器有时也是 可取的。 例如，如果 安装了操作系统级别的严重安全修复，则应立即重新启动服务器。 在 CAS 服务器群中，即使在最繁忙的时候， 滚动重新启动，也很容易实现这一点。

传统上，操作单个服务器会将此类重新启动推迟到不太繁忙的时间，同时运行时会出现已知的 漏洞。 然而，最近随着虚拟机技术的日益接受及其固有的 冗余和故障耐受性，中科院单节点也实现了类似的品质。


## 推荐架构
下图突出了高度可用的 CAS 部署的重要方面。

![推荐 HA 架构](../images/recommended_ha_architecture.png "推荐 HA 架构")

值得指出此架构的一些重要特征：

* 依赖系统最多可承受 N-1 节点故障。 （其中N是节点总数。
* CAS 本身可以容忍多达 N-1 节点故障。
* 缓存节点的丢失不会导致复制缓存中 SSO 状态数据（即票证）的丢失。
* 缓存节点的丢失可能会导致非复制缓存中的 SSO 状态数据丢失（例如 memcached）。
* SSO 状态数据的丢失总是优美的：用户只需重新验证即可。

在详细讨论推荐架构的各个方面之前，我们为规划高度可用的部署提供了指导性 原则：

<div class="alert alert-info"><strong>追求简单</strong><p>设计最简单的解决方案，满足性能和可用性要求。</p></div>

经验表明，简单性是成功和稳健的医管局部署的重要系统特征。 争取简单，你会得到很好的服务。


## 部署方案

### 单节点 CAS，HA VM 基础设施
通过在复杂的虚拟化环境中实现单节点 CAS，可以实现高可用性。 这种高可用性的方法是有吸引力的，因为它简化了CAS服务器配置，但 需要硬件虚拟化技术，可能不存在和可用。

#### 物理架构
在单节点 VM 架构中，CAS 服务器以及必要的先决条件和软件依赖项部署在单个主机 VM 中。 在此部署情景下，默认的内存票证注册表已足够，无需 Servlet 会话复制。 这简化了部署配置，如果 VM 基础设施 足以满足 HA 和可扩展性需求，则建议采用这种方法。

#### 鲁棒性

硬件组件故障/恢复是虚拟化环境的一个特征，因此 CPU、 内存或电源的丢失不会导致 CAS 服务器的故障。

#### 零停机维护方法

此配置无法实现真正的零停机时间维护（即对最终用户没有可观察到的影响）。 但是，通过利用大多数 VM 基础设施的克隆能力，无需停机即可进行维护和升级。 一旦新的 CAS 服务器节点准备好，就可以实施短暂的切割，这将有效地 结束当前所有 SSO 会话。 这可以通过在新的 `cas.war` 部署后，在低流量时安排Tomcat的重启来完成。

#### 可扩展性

CAS 本身的计算要求并不高，因此任何现代企业级服务器硬件 足以在典型部署场景中处理 10，000 个用户。 在最近的一次客户端参与负载测试 单个节点部署取得了良好的结果，CAS 以每秒 61 个请求处理 200 个并发用户，这 大致相当于每小时 108，000 次身份验证交易。 这些数字当然具有代表性 任何基准都将高度依赖当地基础设施。 VM 环境应能够扩展可用的 CPU 和内存，以满足广泛的需求。


### 多个 CAS 服务器节点

高度可用的 CAS 部署由硬件负载平衡器后面的两个或多个节点组成， 主动/被动或主动/主动模式。 一般来说，前者提供简单与 足够的故障转移：后者，改善了资源使用，减少了服务中断，但代价是增加了复杂性。 在主 CAS 节点出现故障的情况下，可通过手动或自动故障转移进行主动被动配置。 通过聚类票证注册表状态，可以进行主动配置，以便任何可用的 CAS 节点 都可以为 CAS 服务器的任何请求提供服务。 [](../ticketing/Configuring-Ticketing-Components.html) ，可以使用共享票务状态实施主动配置。

可以通过在多个虚拟机或物理主机上实施多节点 CAS 部署来实现 HA。 这种方法很有吸引力，因为它允许以部署复杂性略有增加为代价对服务进行真正的零停工维护。

中科院多节点一般涉及以下几个问题：

* 安装 CAS 服务器的多个实例（以便在 CAS 服务不可用的情况下销毁其中一个或多个服务器）
* 将 CAS 服务器的多个实例配置为共享票务状态（以便无论用户或服务与哪个 CAS 服务器进行交互，每个 CAS 服务器的响应都是一样的）。
* 配置用于引导聚类 CAS 服务器之间的流量的解决方案，用于检测组件故障和从服务中删除故障组件
* 可选地，在 CAS 实例中配置用于共享会话状态和会话故障转移的解决方案（这通常不合适，因为最终用户 CAS 会话往往是短暂的，并且体验比面向会话更具有请求响应风格） - 倾向于短寿命粘性（又名持久会话）负载平衡（可能是大型 NAT 部署的问题）
* 制定适当的应急计划，以便在实施时恢复预期的防故障余地。 （例如，有三个 CAS 服务器实例（聚类），提供仅可仅使用两个实例的负载。


#### 物理架构

物理架构可以通过虚拟机或物理硬件实现。 需要注意的是， 共享票务状态模型（活动/活动模式）中，CAS 服务器节点需要能够在所有节点之间传达票证 状态，因此，此类节点之间的防火墙限制需要放宽到足以允许票证状态复制。

服务端点是在负载平衡器上配置的虚拟 IP 地址。 因此，所有请求都由负载平衡器 处理，然后路由到可用的 CAS 节点。


#### 鲁棒性

如果 CAS 节点发生故障，工作负载和身份验证请求可以正确 改道到另一个 CAS 节点。 通过故障转移方案，可能会丢失某些状态 ，具体取决于用户在登录流中的位置，因此，一旦 请求的重新路由从故障节点降落到克隆，则可能需要再次向用户显示 CAS 登录屏幕。 此故障模式可以通过 Servlet 会话状态复制进行消除。

#### 零停机维护方法

维护工作，以便包括升级和应用补丁到 软件可以通过两种一般方法进行：

- 在主动被动模型中，可以在被动 CAS 节点下线执行工作。 然后调整负载平衡器，以便在准备好后切换已准备好的节点，从而 切换主动被动节点。 这会导致所有 CAS SSO 会话被重置，如果在高利用率时期进行，可能会 一些票证验证失败。 有关此方法的更多详细信息，请参阅下文。

- 在活动式模型中，一个节点可以脱机，而至少一个其他 CAS 服务器节点仍然能够对请求进行响应。 升级过程完成后， 服务器可以返回到池中，同时从其他活动节点获取票证状态。 某些 分布式票证注册模型能够通过从其他节点接收票证 数据来引导自己，而无需进行任何手动配置或调整。 有关此方法的更多详细信息，请参阅下文。


#### 可扩展性

只需在聚类中添加新的 CAS 节点即可实现可扩展性。

#### 主动/被动模式

在主动/被动负载平衡配置中，N 节点中的 1 个在任何给定时间提供所有请求。 这简化了 票存储要求，因为无需在多个应用节点之间共享票务状态。

特别是，存储内存中的票证的默认票证注册表组件适用于主动/故障转移 设置，并理解节点故障将导致票证丢失。 值得重复的是，机票丢失 导致优雅的应用程序失败，用户只需重新验证到CAS以创建新的SSO会话： 以前 SSO 会话下创建的 CAS 客户端会话不会中断或丢失数据。


#### 活动/活动模式

处于活动/活动模式的负载平衡器同时向所有 N 节点服务请求。 负载平衡器选择节点 ，以根据配置的算法服务请求：通常最不活跃或循环。 在这个系统架构中， 无论哪个CAS节点要求如何，使用可以找到机票的售票处都至关重要。

讨论这项要求的起源很有启发性。 门票有两个交互， 根本不同的网络来源：

1. 用户的 Web 浏览器联系 CAS 以生成票证。
2. 目标服务使用票证联系 CAS 以验证它。

由于这两个请求都从不同的源地址流经负载平衡器，因此无法保证 这两个请求均由同一 CAS 节点提供服务。 因此，无论 要求票证的CAS节点如何，都要求票证是可选的。 应该清楚为什么内存存储不适合主动/主动部署。

主动架构允许 CAS 服务器版本在 升级时实现零停机时间转换。 一个 CAS 节点实例可以脱机，进行维护，然后重新投入生产。 然后，所有其他 CAS 节点重复相同的策略。

还有一个关于主动/主动部署的进一步考虑：会话亲和力。 会话亲和力是 大多数负载平衡器设备的一个功能，其中设备对传入的请求执行状态管理，并路由客户端在一段时间内 同一节点以进行后续请求。 默认情况下不再需要此功能 因为 CAS 能够直接在客户端维护 CAS 登录/注销 Web 流的状态。 但是，提供了其他 选项，以便在必要时将servlet容器会话存储与复制选项一起使用 。 请参阅本指南 [](../webflow/Webflow-Customization-Sessions.html) 了解更多。


#### 避免循环 DNS

我们 _强烈_ 建议避免循环 DNS 作为硬件负载平衡器的具有成本效益的替代方案。 客户缓存过期政策是完全无法控制的，典型的缓存到期时间比节点故障转移的 理想期限要长得多。 [反向代理](http://httpd.apache.org/docs/current/mod/mod_proxy.html) 或 [软件负载平衡器](http://www.linuxvirtualserver.org/software/ipvs.html) 是硬件的推荐替代品。


### 医管局票务注册处

以下 [票证存储组件](../ticketing/Configuring-Ticketing-Components.html) 在易用性、可扩展性和 故障耐受性之间提供最佳的权衡，并适用于主动/被动和主动/主动设置。

存储技术的特殊选择应受基础设施和专业知识以及性能 和可用性考虑的驱动。 拥有高性能存储几乎毫无价值，因为当问题总是出现时，您缺乏 专业知识来排除故障。

各种存储组件的技术考虑值得讨论，因为影响可用性和性能特性的 差异显著。 像Ehcache和黑兹尔卡斯特这样的缓存系统 提供一个分布式缓存，它提供了一个单一的、一致的条目视图，无论 联系的节点。 分布式缓存依靠复制来提供一致性。 缓存系统（如 memcached 将票证存储在正好 1 节点上，并使用确定算法定位包含票证的节点：

    N '=f（h）T），N1，N2，N3，... Nm）

其中 _h（T）_ 是机票ID的散列， _N1.。。 Nm_ 是缓存节点集， _N'_ 是 _N 的成员。。。 恩姆_。

这些类型的缓存系统不需要复制，通常以牺牲某些 耐用性为代价来提供简单性。

##### 安全缓存复制

一些基于缓存的票证注册机构支持在线路上安全复制票证数据， 以便对门票进行加密，并在复制尝试中签名，以防止嗅探和窃听。 [有关详细信息，请参阅本指南](../installation/Ticket-Registry-Replication-Encryption.html) 。


### 分发服务定义

在 HA 环境中，CAS 集群中的所有节点都必须复制和访问服务定义 。 通常，这可以通过利用由 JPA、LDAP、MongoDb 等 支持的集中 [注册表实施](../services/Service-Management.html) 来实现。 由文件系统支持的注册机构需要设计一个过程，以确保适当的文件 复制，无论是手动还是通过背景护身听。

### 连接池

我们 _强烈_ 建议所有连接到后端数据存储（如 LDAP 目录和数据库）的 IO 连接 尽可能利用连接池。 它充分利用计算 （特别是 SSL/TLS 连接）和 IO 资源，同时提供最佳性能特性。


### 监测

CAS 采用者通常使用已在操作实践中 使用的工具对 CAS 服务的可用性实施监控，以监控其他企业 Web 应用程序。 CAS 引入了一个新的 适度的监控页面，默认由请求者remote_address进行身份验证。


### 渠道保密

渠道保密（通过 SSL/TLS）被假定，对 CAS 系统的安全态势至关重要。 这包括前通道（用户浏览器代理和 CAS 服务器之间）和后通道 （在 Web 应用程序和 CAS 服务器之间）https 流量、负载平衡器或 内容筛选器和 CAS 节点之间的任何中间代理流量，以及主要身份验证（如 LDAPS）和属性分辨率（JDBC 超过 SSL）。 在任何阶段，隐私控制的任何中断都包括系统的整体安全性。


### 升级

CAS服务器升级应通过建议的 [WAR覆盖方法进行](../installation/WAR-Overlay-Installation.html)。 作为最佳 实践，叠加方法允许人们从已知 和公共存储库无缝地获取预期的 CAS 服务器版本，同时在下载的二进制语件上放置特定的自定义更改。 在叠加方法的具体细节中，也可以将 `cas.war` 之外的配置 外部化，以便同一 `cas.war` 文件的属性和记录配置可以因层而异。 即，外部化特定于环境的配置允许将相同的 `cas.war` 从服务器推广到服务器 ，从层升级到层层，这增加了人们的信心，即经过测试和验证的 Web 应用程序在生产中的行为将与测试一样。
